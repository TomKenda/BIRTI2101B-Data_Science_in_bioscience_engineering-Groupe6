{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2 de test_jupyter\n",
    "# Pour différencier des séquences orfs (orf ou gène) de séquences random \n",
    "# Fichier de données : another_try.txt\n",
    "#  -> toutes les sequences ont une longueur de 300 nucleotides de long\n",
    "#  -> les sequences orfs sont ___,gene\n",
    "#  -> les sequences random sont ___,noise\n",
    "# ! ne contient que 446 sequences (223 de chaque)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import\n",
    "import os\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données depuis la database\n",
    "os.chdir(\"/Users/lalou/Desktop/DNA_Sequencing\")\n",
    "file = open(\"another_try.txt\", 'r')\n",
    "# file = open(\"data.txt\", 'r')\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "# Le fichier another_try.txt contient 446 sequences de 300 nucleotides de long dont :\n",
    "#    - 226 orfs\n",
    "#    - 226 non-orfs (créés avec un random.choice(['A', 'T', 'C', 'G']))\n",
    "# Les lignes 'genes' sont les orfs\n",
    "# et les lignes 'noise' sont les non-orfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecteurs contenant les donnees\n",
    "l_used = len(lines)\n",
    "\n",
    "seq = [line.strip().split(\",\")[0] for line in lines][0:l_used]\n",
    "lab = [line.strip().split(\",\")[1] for line in lines][0:l_used]\n",
    "labs = []\n",
    "for i in lab:\n",
    "    if i == \"noise\":\n",
    "        labs.append(0)\n",
    "    else:\n",
    "        labs.append(1)\n",
    "\n",
    "# Longueur de la plus longue séquence\n",
    "m1 = max([len(i) for i in seq])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions de transformation des donnees\n",
    "def nucl_to_numb(letter):\n",
    "    if letter == \"A\":\n",
    "        return [1, 0, 0, 0]\n",
    "    elif letter == \"T\":\n",
    "        return [0, 1, 0, 0]\n",
    "    elif letter == \"G\":\n",
    "        return [0, 0, 1, 0]\n",
    "    elif letter == \"C\":\n",
    "        return [0, 0, 0, 1]\n",
    "    else:\n",
    "        print(\"aie\", letter)\n",
    "        return False\n",
    "    \n",
    "def seq_to_vec(sequence, l_max=m1):\n",
    "    n = []\n",
    "    for nucl in sequence:\n",
    "        n.append(nucl_to_numb(nucl))\n",
    "    while len(n) < m1:\n",
    "        # n.append([0.25, 0.25, 0.25, 0.25])\n",
    "        # n.append([0.00, 0.00, 0.00, 0.00])\n",
    "        n.append([0.125, 0.125, 0.125, 0.125])\n",
    "    return n\n",
    "\n",
    "def vec_to_seq(array):\n",
    "    n = \"\"\n",
    "    for vec in array:\n",
    "        if vec[0] == 1:\n",
    "            n += \"A\"\n",
    "        elif vec[1] == 1:\n",
    "            n += \"T\"\n",
    "        elif vec[2] == 1:\n",
    "            n += \"G\"\n",
    "        elif vec[3] == 1:\n",
    "            n += \"C\"\n",
    "        elif vec[0] == 0.25:\n",
    "            return n\n",
    "        else:\n",
    "            print(\"aie\")\n",
    "    else:\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomisation : chgmt ordre des sequences\n",
    "index = [i for i in range(len(seq))]\n",
    "random.shuffle(index)\n",
    "seq = [seq[i] for i in index]\n",
    "labs = [labs[i] for i in index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom des classes\n",
    "class_names = ['random', 'orf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des couches\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(2)])\n",
    "\n",
    "# keras.layers.Dense(128, activation='relu'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compilation du modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Epoch 1/2\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.6124\n",
      "Epoch 2/2\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9691\n"
     ]
    }
   ],
   "source": [
    "print(m1)\n",
    "\n",
    "# Peu de données, apprentissage classique en une fois\n",
    "\n",
    "#nbre = 6\n",
    "#qtty = 50\n",
    "#for i in range(nbre):\n",
    "#    start = i*qtty\n",
    "#    stop = (i+1)*qtty\n",
    "#    seqs = [seq_to_vec(j) for j in seq[start:stop]]\n",
    "#    array_seq = np.array(seqs)\n",
    "#    array_seq.reshape(-1, qtty, 4)\n",
    "#    array_lab = np.array(labs[start:stop])\n",
    "##    array_lab.reshape(-1, 2, qtty)\n",
    "#    \n",
    "#    model.fit(array_seq, array_lab, epochs=3, batch_size=5)\n",
    "#    \n",
    "#    print(\"Avancée :\", int(100*(i+1)/nbre), \"%\")\n",
    "    \n",
    "seqs = [seq_to_vec(j) for j in seq]\n",
    "# Conversion en numpy Arrays\n",
    "seqs_array = np.array(seqs)\n",
    "seqs_array.reshape(-1,l_used,4)\n",
    "labs_array = np.array(labs)\n",
    "\n",
    "# Entrainer le modele\n",
    "l_bis = int(0.8*l_used)\n",
    "model.fit(seqs_array[0:l_bis], labs_array[0:l_bis], epochs=2, batch_size=10)\n",
    "\n",
    "last_seqs = seqs_array[l_bis:]\n",
    "last_labs = labs_array[l_bis:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 998us/step - loss: 0.1329 - accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Evaluer précision du modèle     \n",
    "test_loss, test_acc = model.evaluate(last_seqs,  last_labs, verbose=1)\n",
    "# print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11980672 0.8801933 ]\n",
      " [0.9470288  0.0529712 ]\n",
      " [0.4165035  0.5834966 ]] [1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Prédictions\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(last_seqs)\n",
    "print(predictions[0:3], last_labs[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGTCTTATTTTGCAGATATAAACTTTAGTACTTTGAGGTCAATGATCCCGCCTTTTACACCCCAACTAGACAGCGAAACTGATGCCGGTTATTTTGATGACTTCACCAGTGAGGCTGACATGGCCAAATATGCTGATGTTTTCAAAAGACAAGACAAATTAACGGCTATGGTAGATGACTCGGCAGTATCATCAAAACTTGTTGGGTTCACTTTCCGACATAGAAATGGTAAACAGGGTTCCAGTGGCATCTTATTCAACGGACTGGAACACTCAGACCCCTTTTCAACCTTTTACTAG\n"
     ]
    }
   ],
   "source": [
    "print(vec_to_seq(last_seqs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir les prédictions\n",
    "\n",
    "results = [[vec_to_seq(last_seqs[i]), last_labs[i], predictions[i][last_labs[i]]] for i in range(len(predictions))]\n",
    "\n",
    "false = []\n",
    "true = [x if x[2] > 0.5 else false.append(x) for x in results]\n",
    "while None in true:\n",
    "    true.remove(None)\n",
    "    \n",
    "f_len = [[len(i[0]), i[1]] for i in false]\n",
    "t_len = [[len(i[0]), i[1]] for i in true]\n",
    "\n",
    "# print(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 90  : badly predicted sequences\n",
      "2 / 3  : gene predicted while orf (orange)\n",
      "1 / 3  : orf predicted while gene (magenta)\n"
     ]
    }
   ],
   "source": [
    "# Longueur des sequences qui ont ete incorrectement predites\n",
    "lenf = [i[0] for i in f_len]\n",
    "labf = [i[1] for i in f_len]\n",
    "lf1, lf2 = [], []\n",
    "for i in range(len(labf)):\n",
    "    if labf[i] == 0:\n",
    "        lf1.append(lenf[i])\n",
    "    else:\n",
    "        lf2.append(lenf[i])\n",
    "\n",
    "# Graphe inutile car toutes les sequences ont exactement la meme longueur\n",
    "#plt.figure(\"False Predictions\")\n",
    "#plt.plot(lf1, color='orange')\n",
    "#plt.plot(lf2, color='magenta')\n",
    "#plt.show()\n",
    "\n",
    "print(len(f_len), \"/\", len(results), \" : badly predicted sequences\")\n",
    "print(len(lf1), \"/\", len(lenf), \" : gene predicted while orf (orange)\")\n",
    "print(len(lf2), \"/\", len(lenf), \" : orf predicted while gene (magenta)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 / 90  : well predicted sequences\n",
      "   -->  45  : well predicted orf (green)\n",
      "   -->  42  : well predicted gene (blue)\n"
     ]
    }
   ],
   "source": [
    "# Longueur des sequences qui ont ete correctement predites\n",
    "lent = [i[0] for i in t_len]\n",
    "labt = [i[1] for i in t_len]\n",
    "lt1, lt2 = [], []\n",
    "for i in range(len(labt)):\n",
    "    if labt[i] == 0:\n",
    "        lt1.append(lent[i]) # orfs\n",
    "    else:\n",
    "        lt2.append(lent[i]) # genes\n",
    "\n",
    "# Graphe inutile car toutes les sequences ont exactement la meme longueur\n",
    "#plt.figure(\"True Predictions\")\n",
    "#plt.plot(sorted(lt1, reverse=False), color='green')\n",
    "#plt.plot(sorted(lt2, reverse=True), color='blue')\n",
    "#plt.show()\n",
    "\n",
    "print(len(t_len), \"/\", len(results), \" : well predicted sequences\")\n",
    "\n",
    "print(\"   --> \", len(lt1), \" : well predicted orf (green)\")\n",
    "print(\"   --> \", len(lt2), \" : well predicted gene (blue)\")\n",
    "\n",
    "# print(len(lt1), \"/\", len(lent), \" : well predicted orf (green)\")\n",
    "# print(len(lt2), \"/\", len(lent), \" : well predicted gene (blue)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séquences 'prédite' : \n",
      "ATGGCTCCCGATACTCTGATGCTAGTAAAGTCAGGTGCCACGAGAAATCGTATAGGTGTGAAAAAGGAGGTTAGGACCTTACTCGATAAAACTTAAAAGATCAATAAAGTGTTTATAAAGTTATATTTTCTACTGCTGATTGAGCTTCATACAGGTGCCGAATGTAATACGAGCAGTTTCCTAGCCACAATTACAGACCCGCCATTTTCTCATGACAAATATAAAGTGACGCTGGTTTTTCAAGAGCGCCCTTGGTATCTAAAATTACCCGCTACTCTAAACAACAGTACCAAATTTTAA\n"
     ]
    }
   ],
   "source": [
    "# model.summary()\n",
    "x = model.trainable_variables\n",
    "# print(x)\n",
    "\n",
    "\n",
    "def get_bias():\n",
    "    x = model.trainable_variables\n",
    "    bias = []\n",
    "    for i in range(len(x)):\n",
    "        if i % 2 != 0:\n",
    "            bias.append(x[i].numpy())\n",
    "    return bias\n",
    "\n",
    "def get_params():\n",
    "    x = model.trainable_variables\n",
    "    params = []\n",
    "    for i in range(len(x)):\n",
    "        if i % 2 == 0:\n",
    "            params.append(x[i].numpy())\n",
    "    return params\n",
    "\n",
    "def get_structure():\n",
    "    p = get_params()\n",
    "    struct = [i for i in p[0].shape]\n",
    "    for i in p[1:]:\n",
    "        struct += [i.shape[1]]\n",
    "    return struct\n",
    "\n",
    "def relu_inv(y, bias = 0):\n",
    "    # y = max(0, x+bias)\n",
    "    x = y-bias\n",
    "    if x < 0:\n",
    "        # ?\n",
    "        return 0\n",
    "    return x\n",
    "\n",
    "def aggregate_inv(x_out, weights):\n",
    "    # x_out = [0, 1]                     de la couche suivante\n",
    "    # weights = [...].shape = (4, 2)     entre les deux couches\n",
    "    # return [sum([w_i[j]*x_out[j] for j in range(len(x_out))]) for w_i in weights]\n",
    "    a_in = []\n",
    "    for w_i in weights:\n",
    "        products = [w_i[j]*x_out[j] for j in range(len(x_out))]\n",
    "        a_in.append(sum(products))\n",
    "    return a_in    \n",
    "\n",
    "def normalize(vector):\n",
    "    # s = max(vector)\n",
    "    # s = max(max(vector), abs(min(vector)))\n",
    "    s = sum(vector)/len(vector)\n",
    "    return [i/s for i in vector]\n",
    "\n",
    "def do_prediction(output = [0, 1]):\n",
    "    bias = get_bias()\n",
    "    params = get_params()\n",
    "    struct = get_structure()\n",
    "    layers = [[0]*i for i in struct]\n",
    "    layers[-1] = output\n",
    "    steps = 2*(len(layers)-2) +1 # 2 par couche cachee + 1 pour la derniere\n",
    "    i = 0\n",
    "    while i < (steps-1)/2:\n",
    "        #print('i', i)\n",
    "        agg = aggregate_inv(layers[-(i+1)], params[-(i+1)])\n",
    "        # print('agg', len(agg))\n",
    "        # print('bias', len(bias), len(bias[-(i+1)]), len(bias[-(i+2)]))\n",
    "        layers[-(i+2)] = [relu_inv(agg[j], bias[-(i+2)][j]) for j in range(len(agg))]\n",
    "        i += 1\n",
    "    else:\n",
    "        layers[0] = aggregate_inv(layers[1], params[0])\n",
    "    # vecteur 4 par 4\n",
    "    vec = []\n",
    "    i = 0\n",
    "    while i < len(layers[0]):\n",
    "        vec.append(layers[0][i:i+4])\n",
    "        i += 4\n",
    "    else:\n",
    "        return vec\n",
    "    return layers[0]\n",
    "\n",
    "def clarify(vec, hidden=-1, other=0):\n",
    "    # Retourne un vecteur correspondants aux lettres\n",
    "    propre = []\n",
    "    for i in vec:\n",
    "        propre.append([0, 0, 0, 0])\n",
    "        if max(i) > hidden:\n",
    "            propre[-1][i.index(max(i))] = 1\n",
    "        else:\n",
    "            propre[-1] = [other]*4\n",
    "    return propre\n",
    "\n",
    "def clarify2(vec):\n",
    "    new = []\n",
    "    for i in vec:\n",
    "        m = abs(min(i))\n",
    "        n = [m+j for j in i]\n",
    "        m = max(n)\n",
    "        n1 = [j/m for j in n]\n",
    "        new.append(n1)\n",
    "    return new\n",
    "    \n",
    "pred = do_prediction([0,1])\n",
    "# for i in pred:\n",
    "#     print(i)\n",
    "# print(len(do_prediction()))\n",
    "# plt.matshow(clarify2(pred)[0:5]+clarify2(pred)[-5:])\n",
    "plt.figure()\n",
    "plt.matshow(clarify(pred, 0.03, 0))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(\"Séquences 'prédite' :\", \"\\n\"+vec_to_seq(clarify(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification des predictions realisees\n",
    "c = 0 #tot\n",
    "s1 = 0 #non-orf\n",
    "s2 = 0 #orf\n",
    "for i in predictions:\n",
    "    c += 1\n",
    "    if i[0] > i[1]:\n",
    "        s1 += 1\n",
    "    elif i[0] < i[1]:\n",
    "        s2 += 1\n",
    "    else:\n",
    "        print(\"Waow\")\n",
    "print(c, s1, s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
